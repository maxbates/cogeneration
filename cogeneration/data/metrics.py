from typing import Dict, Optional

import mdtraj as md
import numpy as np
import numpy.typing as npt
import torch

from cogeneration.data import residue_constants
from cogeneration.data.const import CA_IDX
from cogeneration.dataset.process_pdb import process_pdb_file
from cogeneration.type.dataset import DatasetProteinColumn as dpc
from cogeneration.type.metrics import MetricName


def t_stratified_loss(
    batch_t: torch.Tensor,
    batch_loss: torch.Tensor,
    num_bins: int = 4,
    loss_name: Optional[str] = None,
):
    """Stratify loss by binning t."""
    batch_t = batch_t.detach().cpu().numpy()
    batch_loss = batch_loss.detach().cpu().numpy()

    flat_losses = batch_loss.flatten()
    flat_t = batch_t.flatten()
    bin_edges = np.linspace(0.0, 1.0 + 1e-3, num_bins + 1)
    bin_idx = np.sum(bin_edges[:, None] <= flat_t[None, :], axis=0) - 1
    t_binned_loss = np.bincount(bin_idx, weights=flat_losses)
    t_binned_n = np.bincount(bin_idx)
    stratified_losses = {}
    if loss_name is None:
        loss_name = "loss"
    for t_bin in np.unique(bin_idx).tolist():
        bin_start = bin_edges[t_bin]
        bin_end = bin_edges[t_bin + 1]
        t_range = f"{loss_name} t=[{bin_start:.2f},{bin_end:.2f})"
        range_loss = t_binned_loss[t_bin] / t_binned_n[t_bin]
        stratified_losses[t_range] = range_loss
    return stratified_losses


def calc_ca_ca_metrics(
    ca_pos: npt.NDArray,  # (N, 3)
    residue_index: Optional[npt.NDArray] = None,  # (N,)
    bond_tol=0.1,
    clash_tol=1.0,  # angstrom, 1.5 in AF2 multimer
) -> Dict[MetricName, float]:
    """
    Calculate metrics for the backbone CA-CA distances of a protein structure.
    """
    ca_bond_dists = np.linalg.norm(ca_pos - np.roll(ca_pos, 1, axis=0), axis=-1)[1:]

    # mask out non-neighboring residues, handle chain gaps
    if residue_index is not None:
        has_no_gap_mask = (residue_index[1:] - residue_index[:-1]) == 1
        ca_bond_dists = ca_bond_dists[has_no_gap_mask]

    ca_ca_dev = np.mean(np.abs(ca_bond_dists - residue_constants.ca_ca))
    ca_ca_valid = np.mean(ca_bond_dists < (residue_constants.ca_ca + bond_tol))

    ca_ca_dists2d = np.linalg.norm(ca_pos[:, None, :] - ca_pos[None, :, :], axis=-1)
    inter_dists = ca_ca_dists2d[np.where(np.triu(ca_ca_dists2d, k=0) > 0)]
    clashes = inter_dists < clash_tol

    return {
        MetricName.ca_ca_deviation: ca_ca_dev,
        MetricName.ca_ca_valid_percent: ca_ca_valid,
        MetricName.num_ca_ca_clashes: np.sum(clashes),
    }


def calc_aatype_metrics(generated_aatypes) -> Dict[MetricName, float]:
    """
    Calculate metrics for the amino acid types generated by a model.
    """
    # generated_aatypes (B, N)
    unique_aatypes, raw_counts = np.unique(generated_aatypes, return_counts=True)

    # pad with 0's in case it didn't generate any of a certain type
    clean_counts = []
    for i in range(20):
        if i in unique_aatypes:
            clean_counts.append(raw_counts[np.where(unique_aatypes == i)[0][0]])
        else:
            clean_counts.append(0)

    # from the scope128 dataset
    reference_normalized_counts = [
        0.0739,
        0.05378621,
        0.0410424,
        0.05732177,
        0.01418736,
        0.03995128,
        0.07562267,
        0.06695857,
        0.02163064,
        0.0580802,
        0.09333149,
        0.06777057,
        0.02034217,
        0.03673995,
        0.04428474,
        0.05987899,
        0.05502958,
        0.01228988,
        0.03233601,
        0.07551553,
    ]

    reference_normalized_counts = np.array(reference_normalized_counts)

    normalized_counts = np.array(clean_counts) / np.sum(clean_counts)

    # compute the hellinger distance between the normalized counts
    # and the reference normalized counts

    hellinger_distance = np.sqrt(
        np.sum(
            np.square(np.sqrt(normalized_counts) - np.sqrt(reference_normalized_counts))
        )
    )

    return {MetricName.aatype_histogram_dist: hellinger_distance}


def calc_mdtraj_metrics(pdb_path: str) -> Dict[MetricName, float]:
    """
    Calculate trajectory metrics, secondary structure metrics
    """
    try:
        traj = md.load(pdb_path)
        pdb_ss = md.compute_dssp(traj, simplified=True)
        pdb_coil_percent = np.mean(pdb_ss == "C")
        pdb_helix_percent = np.mean(pdb_ss == "H")
        pdb_strand_percent = np.mean(pdb_ss == "E")
        pdb_ss_percent = pdb_helix_percent + pdb_strand_percent
        pdb_rg = md.compute_rg(traj)[0]
    except IndexError as e:
        print("Error: in calc_mdtraj_metrics: {}".format(e))
        pdb_ss_percent = 0.0
        pdb_coil_percent = 0.0
        pdb_helix_percent = 0.0
        pdb_strand_percent = 0.0
        pdb_rg = 0.0

    return {
        MetricName.non_coil_percent: pdb_ss_percent,
        MetricName.coil_percent: pdb_coil_percent,
        MetricName.helix_percent: pdb_helix_percent,
        MetricName.strand_percent: pdb_strand_percent,
        MetricName.radius_of_gyration: pdb_rg,
    }


def calc_scaffold_mdtraj_metrics(
    pdb_path: str,
    scaffold_mask: Optional[npt.NDArray],  # (N,) bool, True for scaffold residues
) -> Dict[MetricName, float]:
    """
    Compute scaffold-only DSSP composition on the PDB corresponding to the top sample.

    Notes:
    - The mask should align with sequence order written in the PDB (same residue ordering used to write it).
    - When mask is None or empty, returns zeros.
    """
    metrics: Dict[MetricName, float] = {}

    if scaffold_mask is None or scaffold_mask.size == 0 or not scaffold_mask.any():
        return metrics

    try:
        traj = md.load(pdb_path)
        dssp = md.compute_dssp(traj, simplified=True)  # (1, N)
        dssp = dssp[0]
        if scaffold_mask.shape[0] != dssp.shape[0]:
            return metrics
        sel = scaffold_mask.astype(bool)
        metrics[MetricName.scaffold_coil_percent] = float(np.mean(dssp[sel] == "C"))
        metrics[MetricName.scaffold_helix_percent] = float(np.mean(dssp[sel] == "H"))
        metrics[MetricName.scaffold_strand_percent] = float(np.mean(dssp[sel] == "E"))
    except Exception:
        pass

    return metrics


def calc_scaffold_plddt_mean(
    pdb_path: str,
    scaffold_mask: npt.NDArray,  # (N,) True for scaffold residues
) -> Dict[MetricName, float]:
    """
    Compute mean pLDDT over scaffold residues only.
    """
    metrics: Dict[MetricName, float] = {}

    try:
        folded_feats = process_pdb_file(
            pdb_file_path=pdb_path,
            pdb_name="",
        )
        plddt_ca = folded_feats[dpc.b_factors][:, CA_IDX]

        assert plddt_ca.shape[0] == scaffold_mask.shape[0]
        sel = scaffold_mask.astype(bool)
        metrics[MetricName.scaffold_plddt_mean] = plddt_ca[sel].mean()

    except Exception:
        pass

    return metrics
