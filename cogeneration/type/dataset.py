from typing import Dict, Union

import pandas as pd
from numpy import typing as npt

from cogeneration.type.str_enum import StrEnum


class DatasetColumns(StrEnum):
    """Columns in the training/synthetic/redesign/test metadata CSVs"""

    pdb_name = "pdb_name"
    raw_path = "raw_path"  # original PDB file (optional)
    processed_path = "processed_path"  # pkl file
    quaternary_category = "quaternary_category"
    oligomeric_count = "oligomeric_count"  # num non-unique sequences
    oligomeric_detail = "oligomeric_detail"  # per-unique seq details
    num_chains = "num_chains"
    seq_len = "seq_len"  # total number of atoms
    modeled_seq_len = "modeled_seq_len"  # max - min res number
    moduled_num_res = "moduled_num_res"  # (new) num residues in modeled structure
    coil_percent = "coil_percent"
    helix_percent = "helix_percent"
    strand_percent = "strand_percent"
    radius_gyration = "radius_gyration"

    # TODO add in process_pdb_files if provided
    resolution = "resolution"
    structure_method = "structure_method"

    # cluster metadata (added by loading clusters csv)
    cluster = "cluster"

    # redesign columns
    example = "example"
    best_seq = "best_seq"  # best 1 redesign per structure
    best_rmsd = "best_rmsd"

    # added during load
    index = "index"


class DatasetProteinColumns(StrEnum):
    """
    Information about the protein, pickled in `processed_path`, or from parsing a Protein / Chain.
    Most of these values are defined by `process_chain` and `parse_chain_feats`.

    The saved proteins contain all molecules / residues, and is of length P.
    `modeled_idx` is length N, and defines which residues are modeled.
    It is used to select these out of the pickled file, then dropped almost immediately in loading / processing.

    Most fields and values seem straightforward from parsing the PDB file, but there are some oddities / potential bugs.

    For example, looking at `10mh`:
    1. 2 DNA molecules are included as chains and the protein is classified as a trimer.
    This is debatable, but reasonable, since the protein is binding something, and shouldn't be treated as a homomer.
    2. The chain IDs in the `pkl` are 26 (protein), 27 (DNA), 28 (DNA).
    There are some heteroatoms but unclear where these numbers come from. Probably not important that they are so high?
    """

    aatype = "aatype"  # (P, ) AA sequence residue indices
    atom_positions = "atom_positions"  # (P, 37, 3) all atom positions
    atom_mask = "atom_mask"  # (P, 37) all atoms to consider
    bb_mask = "bb_mask"  # (P, ) alpha carbons considered
    bb_positions = "bb_positions"  # (P, 3) alpha carbon
    residue_index = "residue_index"  # (P, ) residue index
    chain_index = "chain_index"  # (P, ) chain index
    b_factors = "b_factors"  # (P, 37) b factors
    modeled_idx = "modeled_idx"  # (N, ) index of modeled residues


class DatasetTransformColumns(StrEnum):
    """
    Columns generated by OpenFold data transform
    """

    # atom37_to_frames()
    rigidgroups_gt_frames = "rigidgroups_gt_frames"
    rigidgroups_gt_exists = "rigidgroups_gt_exists"
    rigidgroups_group_exists = "rigidgroups_group_exists"
    rigidgroups_group_is_ambiguous = "rigidgroups_group_is_ambiguous"
    rigidgroups_alt_gt_frames = "rigidgroups_alt_gt_frames"
    # atom37_to_torsion_angles()
    torsion_angles_sin_cos = "torsion_angles_sin_cos"


"""NumpyFeat is a feature in primitive or numpy"""
NumpyFeat = Union[npt.NDArray, str, int]

"""MetadataCSVRow type alias for a single row of the metadata CSV file"""
MetadataCSVRow = Dict[DatasetColumns, NumpyFeat]

"""MetadataDataFrame type alias for the metadata CSV file, composed of MetadataCSVRow"""
MetadataDataFrame = pd.DataFrame

"""ProcessedFile for pre-processed pkl, produced by `parse_pdb_files.py`"""
ProcessedFile = Dict[DatasetProteinColumns, NumpyFeat]
